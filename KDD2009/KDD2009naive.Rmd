---
title: "KDD2009naive"
author: "Win-Vector LLC"
date: "November 9, 2015"
output: html_document
---

[KDD2009 naive example](http://www.sigkdd.org/kdd-cup-2009-customer-relationship-prediction).  Winners had hold-out AUC of 0.7611 on churn.   See [here](https://github.com/WinVector/zmPDSwR/tree/master/KDD2009) for more details.

This file is now not to do things (fixing problems as you find them).  Instead use a
systmetic variable tranformer such as [vtreat](https://github.com/WinVector/vtreat).


```{r kddexlibs, tidy=FALSE}
print(date())
#load some libraries
# http://www.win-vector.com/blog/2014/08/vtreat-designing-a-package-for-variable-treatment/
library('vtreat')
# devtools::install_github("WinVector/WVPlots")
library('WVPlots')

library('parallel')
library('gbm')
library('ggplot2')
library('glmnet')


# load the data as in the book
# change this path to match your directory structure
dir = './' 
debug = FALSE


d = read.table(paste(dir,'orange_small_train.data.gz',sep=''),
                header=T,sep='\t',na.strings=c('NA',''), 
               stringsAsFactors=FALSE)
churn = read.table(paste(dir,'orange_small_train_churn.labels.txt',sep=''),
                    header=F,sep='\t')
d$churn = churn$V1
appetency = read.table(paste(dir,'orange_small_train_appetency.labels.txt',sep=''),
                        header=F,sep='\t')
d$appetency = appetency$V1
upselling = read.table(paste(dir,'orange_small_train_upselling.labels.txt',sep=''),
                        header=F,sep='\t')
d$upselling = upselling$V1
set.seed(729375)
rgroup = runif(dim(d)[[1]])
dTrainM = d[rgroup<=0.9,]  # set for building models
dTest = d[rgroup>0.9,] # set for evaluation
if(debug) {
  dTrainM <- dTrainM[sample.int(nrow(dTrainM),1000),]
  dTest <- dTest[sample.int(nrow(dTest),1000),]
}
rm(list=c('d','churn','appetency','upselling','dir'))
outcomes = c('churn','appetency','upselling')
nonvars <- c(outcomes,'rgroup')
vars = setdiff(colnames(dTrainM),
                nonvars)
yName = 'churn'
yTarget = 1
print(date())
```

```{r kddprint, tidy=FALSE}
print(summary(dTrainM))
```


The above data will not work with many machine learning algorithms (for example logistic regression, or random forests) due to implementations not liking at least one the many NA entries, and the presence of large categoricals.  In addition many R implementations only accept a limited number of independent variable types.  We will perform the minimum amount of "fixing" to make this dataset usable, however the transformations are complicated and in no sense optimal.

What we will do is:
 
 * Change logical to numeric.
 * Change numeric NA to 0.
 * Temporarily change all factors to character types (to make sure there are no unused levels).
 * Change all character NA and levels not seen during training to "" (blank).
 * Then change all character types to factor (as this is what gbm accepts, though we are using glm).
 * Limit down only input variables that have more than one value and categoricals that have no more than 200 values.
 
This "minimal" set of transformations is a bit involved, is not very faithful to the original data, and still may miss corner cases.  This is why this step is worth automating.
 

```{r kdddesign, tidy=FALSE}
print(date())
# naively transform data
cleanColumn <- function(c,targetSet) {
  if(is.logical(c)) {
    c <- as.numeric(c)
  }
  if(is.numeric(c)) {
    c[is.na(c)] <- 0
  }
  if(is.factor(c)) {
    c <- as.character(c)
  }
  if(is.character(c)) {
    c[is.na(c)] <- ''
    if(!is.null(targetSet)) {
      c[!(c %in% targetSet)] <- ''
    }
  }
  c
}
treatedTrainM <- dTrainM
treatedTest <- dTest
for(cn in vars) {
  treatedTrainM[[cn]] <- cleanColumn(dTrainM[[cn]],NULL)
  treatedTest[[cn]] <- cleanColumn(dTest[[cn]],unique(treatedTrainM[[cn]]))
  if(is.character(treatedTrainM[[cn]])) {
     levs <- sort(unique(c('',treatedTrainM[[cn]])))
     treatedTrainM[[cn]] <- factor(treatedTrainM[[cn]],levs)
     treatedTest[[cn]] <- factor(treatedTest[[cn]],levs)
  }
}
treatedTrainM[[yName]] = treatedTrainM[[yName]]==yTarget
treatedTest[[yName]] = treatedTest[[yName]]==yTarget
canUse <- vapply(vars,
                 function(cn) { (length(unique(treatedTrainM[[cn]]))>1) &&
                     ( (!is.factor(treatedTrainM[[cn]])) ||
                         (length(unique(treatedTrainM[[cn]]))<=200) ) },
                 logical(1))
selvars <- vars[canUse]
print(date())
```





```{r kddmodels1, tidy=FALSE}
print(date())
print(selvars)

# look for novel levels in test
hasNoNovelLevels <- logical(nrow(treatedTest))
hasNoNovelLevels <- TRUE
for(v in vars) {
  if(is.factor(treatedTrainM[[v]])) {
     hasNoNovelLevels <- hasNoNovelLevels & (treatedTest[[v]] %in% unique(treatedTrainM[[v]]))
  }
}
print(summary(hasNoNovelLevels))

# prepare plotting frames
treatedTrainP = treatedTrainM[, yName, drop=FALSE]
treatedTestP = treatedTest[, yName, drop=FALSE]

formulaS = paste(yName,paste(selvars,collapse=' + '),sep=' ~ ')
```

Try gbm modeling.

```{r kddmodel1e, error=TRUE}
# errors out, presumably during its own cross val!
modelGBMs = gbm(as.formula(formulaS),
                data=treatedTrainM,
                distribution='bernoulli',
                n.trees=1000,
                interaction.depth=3,
                keep.data=FALSE,
                cv.folds=5)
```



```{r kddmodels2,tidy=FALSE}
# try again without cross val, giving up features to get a run.
mname = 'gbmPred'
modelGBMs = gbm(as.formula(formulaS),
                data=treatedTrainM,
                distribution='bernoulli',
                n.trees=1000,
                interaction.depth=3,
                keep.data=FALSE)
#print(modelGBMs)
#print(summary(modelGBMs))
nTrees = gbm.perf(modelGBMs)
treatedTrainP[[mname]] = predict(modelGBMs,
                                 newdata=treatedTrainM,type='response',
                                 n.trees=nTrees)


t1 = paste(mname,'train data')
print(DoubleDensityPlot(treatedTrainP, mname, yName, 
                        title=t1))
print(ROCPlot(treatedTrainP, mname, yName, 
              title=t1))
t2 = paste(mname,'test data')
treatedTestP[[mname]] = predict(modelGBMs,
                                    newdata=treatedTest,type='response',
                                    n.trees=nTrees)
print(DoubleDensityPlot(treatedTestP, mname, yName, 
                        title=t2))
print(ROCPlot(treatedTestP, mname, yName, 
              title=t2))
print(date())
```

Try elastic net glm modeling.  No formula intervace, so we have to call model matrix ourselves.
We go to the trouble of binding the data together to gaurantee a joint encoding (deals
with both issues of novel levels and missing levels which arise when the set of levels
seen in training and test are not the same).

```{r} 
nTrain <- nrow(treatedTrainM)
jointData <- rbind(treatedTrainM[,selvars,drop=FALSE],treatedTest[,selvars,drop=FALSE])
jointData <- model.matrix(as.formula(paste('',paste(selvars,collapse=' + '),sep=' ~ ')),
                                        jointData)
# get rid of intercept
jointData <- jointData[,-1]
mvars <- colnames(jointData)
# put back in frames
treatedTrainJ <- jointData[seq_len(nTrain),]
treatedTestJ <- jointData[-seq_len(nTrain),]
```



```{r}
mname = 'glmPred'
modelglms = cv.glmnet(x = treatedTrainJ,
                      y = treatedTrainM[[yName]],
                      alpha=0.5,
                      family='binomial')
#print(summary(modelglms))
treatedTrainP[[mname]] = as.numeric(predict(modelglms,
                                            newx=treatedTrainJ,
                                            type='response'))
treatedTestP[[mname]] = as.numeric(predict(modelglms,
                                           newx=treatedTestJ,
                                           type='response'))
t1 = paste(mname,'train data')
print(DoubleDensityPlot(treatedTrainP, mname, yName, 
                        title=t1))
print(ROCPlot(treatedTrainP, mname, yName, 
              title=t1))
t2 = paste(mname,'test data')
print(DoubleDensityPlot(treatedTestP, mname, yName, 
                        title=t2))
print(ROCPlot(treatedTestP, mname, yName, 
              title=t2))
```

Practical Data Science with R's
demonstration avoided this over-fit by pruning variables in a y-away way on a
set disjoint from the preperation set.  

We have documented and automated a consistent workflow using 
_vtreat::mkCrossFrameCExperiment_ that extracts as much fitting power as practical.

